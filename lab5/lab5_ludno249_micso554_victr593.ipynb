{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**Due date:** 2017-02-24\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students:** Ludvig Noring (ludno249), Michael Sörsäter (micso554), Victor Tranell (victr593)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **word space model** of word meanings represents words as vectors in a high-dimensional vector space. In this lab you will experiment with a word space model which trained on the Swedish Wikipedia using [word2vec](https://code.google.com/archive/p/word2vec/). In order to use word2vec in Python, we use the [gensim](https://radimrehurek.com/gensim/) library.\n",
    "\n",
    "The library and some more essentials for this lab are contained in the module we load in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nlp5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the lab system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load the pre-trained word space model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = nlp5.load_model(\"/home/TDDE09/labs/nlp5/data/wikipedia-sv.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of word vectors. In Python a word vector is represented as an [*array*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html). For the purposes of this lab, you can treat arrays as lists. The next line of code prints the vector for the word *student*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38911471, -0.25333604,  0.10631166,  0.36140671,  0.14798231,\n",
       "       -0.28869128,  0.4014135 , -1.01921523, -0.00860699,  0.76315218,\n",
       "       -0.30077016,  0.31991726, -0.30887559, -0.21920508, -0.10915887,\n",
       "        0.41282091, -0.23703265,  0.93853813,  0.81494588,  0.01140385,\n",
       "        0.24421778,  0.3621935 ,  0.44512981,  0.32729414,  0.82020354,\n",
       "       -0.79330653, -0.044444  , -0.42768687, -0.88712269,  0.13306266,\n",
       "        0.57084686,  0.46596572, -0.48475036,  0.22611499,  0.36376789,\n",
       "        0.12183799,  0.71142977,  0.33212078,  1.33993554, -0.78250617,\n",
       "       -0.60445988,  0.0656125 , -0.18711154,  0.70977861,  0.11466026,\n",
       "        0.36936972,  0.19929321, -0.41768453,  0.88794357, -0.49968722,\n",
       "       -0.53722715, -0.32763621, -0.05238692, -0.21328461,  0.68021107,\n",
       "       -0.49659464,  0.78859437,  0.51455098,  0.59885758,  0.31225756,\n",
       "       -0.47549149,  0.12143688,  0.79769266, -0.1092938 ,  0.05594372,\n",
       "        0.94904387,  1.13171613, -0.23624501,  0.31303319, -0.4595733 ,\n",
       "        0.02605049,  1.03642654,  0.26993337, -0.01846636, -0.75967073,\n",
       "       -0.41027161, -0.13498557,  0.43224856, -0.41064134, -0.48234031,\n",
       "        0.21146171,  0.07388449,  0.01523833, -0.26064622,  1.04802608,\n",
       "        0.55496365,  0.05995376,  0.39918602,  0.28152168,  0.13333985,\n",
       "        0.5695802 , -0.4568519 , -0.27244726,  0.17847468,  0.14035679,\n",
       "       -0.40522844, -0.98898071, -0.41696772, -0.33668745,  0.56312728], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['student']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All vectors in the model have the same dimensionality $n$; this value is a parameter that is fixed when training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 1</div>\n",
    "<div class=\"panel-body\">\n",
    "Write some code that prints $n$ for the model we loaded earlier.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(model['student']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a word space model, we can compute the semantic similarity between words using the cosine distance between their respective word vectors. The next line of code showcases how to compute the cosine distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67229160209\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('student', 'lärare'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 2</div>\n",
    "<div class=\"panel-body\">\n",
    "<p>Write code to print the following:</p>\n",
    "<ul>\n",
    "<li>the cosine distance between a word and the word itself</li>\n",
    "<li>the cosine distance between two words that are, according to your judgement, semantically related</li>\n",
    "<li>the cosine distance between two words that are, according to your judgement, semantically unrelated</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.840633706043\n",
      "0.396592828848\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('tomato', 'tomato'))\n",
    "print(model.similarity('kaviar', 'knäckebröd'))\n",
    "print(model.similarity('kaviar', 'betong'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a word analogy task you are given two pairs of words that share a common semantic relation. A well-known example is *man/woman* and *king/queen*, where the semantic relation could be dubbed &lsquo;female&rsquo;. The task is to predict one of the words, e.g. *queen*, given the other three. By doing that we answer the question: &lsquo;*man* is to *woman* as *king* is to —?&rsquo;.\n",
    "\n",
    "### Predict the fourth word\n",
    "\n",
    "[Mikolov et al. (2013)](http://www.aclweb.org/anthology/N13-1090) have shown that the word analogy task can be solved by adding and substracting word vectors in a word2vec-model: the vector for *queen* is close (in terms of cosine distance) to the vector *king* $-$ *man* $+$ *woman*. In the next problem you will implement this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 3</div>\n",
    "<div class=\"panel-body\">\n",
    "Write a function `complete()` that takes the first three words of a word analogy quadruple as input and predicts the fourth word.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "To solve the problem you should complete the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def complete(model, a, b, c):\n",
    "    \"\"\"Returns the fourth word in the analogy quadruple\"\"\"\n",
    "    word, score = model.most_similar([c, b], [a], 1)[0]    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is supposed to be called like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drottning\n",
      "andningsuppehåll\n"
     ]
    }
   ],
   "source": [
    "print(complete(model, \"man\", \"kvinna\", \"kung\"))\n",
    "print(complete(model, \"tenta\", \"plugg\", \"ångest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Problem&nbsp;3 you can use the following method of the model:\n",
    "\n",
    "`model.most_similar(pos, neg, n)`\n",
    "\n",
    "The method takes as its inputs two lists with words (strings), `pos` and `neg`, and a number `n`, and returns the `n` closest vectors to the vector that one gets by adding all the vectors in the `pos` list and subtracting all the vectors in the `neg` list. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('drottning', 0.7310913801193237), ('tronföljare', 0.7307088971138), ('prinsessa', 0.7277407646179199)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(['kung', 'kvinna'], ['man'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories of analogies\n",
    "\n",
    "Word vectors are computed based on co-occurrence counts: words that co-occur frequently with certain other words are going to have similar vectors. In order to get a better understanding of the model&rsquo;s possibilities and limitations, we load a list of ten analogy pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analogies = nlp5.load_data(\"/home/TDDE09/labs/nlp5/data/analogies.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 4</div>\n",
    "<div class=\"panel-body\">\n",
    "<p>\n",
    "Write code that computes the model&rsquo;s accuracy on the task of predicting the fourth word in every analogy pair, given the other three. Feel free to use your `complete()`-function.\n",
    "</p>\n",
    "<p>\n",
    "Analyse the mistakes that the model make and write a short explanation. Ground your explanations in your understanding of the basic distributional principle that underlies word space models.\n",
    "</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Use the next code cell to solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stockholm Sverige Berlin Tyskland\n",
      "Predicted: Tyskland\n",
      "\n",
      "Östergötland Linköping Södermanland Nyköping\n",
      "Predicted: Nyköping\n",
      "\n",
      "USA dollar Sverige krona\n",
      "Predicted: kronor\n",
      "\n",
      "Sverige svensk Frankrike fransk\n",
      "Predicted: fransk\n",
      "\n",
      "kvinna man syster bror\n",
      "Predicted: bror\n",
      "\n",
      "stor liten gammal ung\n",
      "Predicted: pojke\n",
      "\n",
      "stor större liten mindre\n",
      "Predicted: mindre\n",
      "\n",
      "stor störst liten minst\n",
      "Predicted: starkast\n",
      "\n",
      "cykla cyklade gå gick\n",
      "Predicted: gick\n",
      "\n",
      "bil bilar människa människor\n",
      "Predicted: människor\n",
      "\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, analogies):\n",
    "    \"\"\"Computes the accuracy of the specified model on the specified list of analogy quadruples\"\"\"\n",
    "    res = [(complete(model, a, b, c), gold) for a, b, c, gold in [x.split() for x in analogies]]\n",
    "\n",
    "    accuracy = []\n",
    "    for i, (pred, golden) in enumerate(res):\n",
    "        print(analogies[i])\n",
    "        print(\"Predicted: {0}\".format(pred))\n",
    "        accuracy.append(pred == golden)\n",
    "        print()\n",
    "        \n",
    "    return sum(accuracy) / len(accuracy)\n",
    "\n",
    "print(evaluate(model, analogies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairs that are related to eachother seems to be more accurate.\n",
    "\n",
    "We predict \"stor liten gammal ung\" wrong because \"stor liten\" is not very related to \"gammal ung\".\n",
    "\n",
    "\"USA dollar Sverige krona\" is almost correct but we probably miss because of the ambiguity in dollar's grammatical number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 5</div>\n",
    "<div class=\"panel-body\">\n",
    "The analogies in the example file have been picked from ten different categories. Invent names for these categories. Which categories would you call syntactic in nature, which syntactic? Choose four categories and find a new example for each of them. Choose two examples where the model succeeds in reproducing the analogy and two where it fails.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Huvudstäder         Stockholm Sverige Berlin Tyskland\n",
    "Svenska städer      Östergötland Linköping Södermanland Nyköping\n",
    "Nationalitet        Sverige svensk Frankrike fransk\n",
    "Valuta              USA dollar Sverige krona\n",
    "\n",
    "Syntactic categories:\n",
    "Antonymer           kvinna man syster bror\n",
    "Preteritum          cykla cyklade gå gick\n",
    "Numerus             bil bilar människa människor\n",
    "Antonymer           stor liten gammal ung\n",
    "Komparativ          stor större liten mindre\n",
    "Superlativ          störst liten minst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Köpenhamn Danmark Paris Frankrike\n",
      "Predicted: Frankrike\n",
      "\n",
      "flyga flög prata pratade\n",
      "Predicted: pratade\n",
      "\n",
      "bra bättre ful fulare\n",
      "Predicted: vackrare\n",
      "\n",
      "Tyskland Euro Thailand Bath\n",
      "Predicted: MX\n",
      "\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "new_examples = [\n",
    "    'Köpenhamn Danmark Paris Frankrike',\n",
    "    'flyga flög prata pratade',\n",
    "    'bra bättre ful fulare',\n",
    "    'Tyskland Euro Thailand Bath'\n",
    "]\n",
    "print(evaluate(model, new_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground\n",
    "\n",
    "Next to the ten categories from the previous problem, there are also other categories the model &lsquo;understands&rsquo;. Here are some examples:\n",
    "\n",
    "* ``Frankrike vin Sverige ?``\n",
    "* ``Jesus kristendom Buddha ?``\n",
    "* ``Tyskland Hitler Italien ?``\n",
    "\n",
    "Your next task will be to find some examples of your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 6</div>\n",
    "<div class=\"panel-body\">\n",
    "Find at least eight new word analogies (like above) from new categories and write code to see if the model &lsquo;understands&rsquo; them. Try to find at least one example from a syntactic category. Summarise your results in a short reflective text.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hockey klubba tennis racket\n",
      "Predicted: racket\n",
      "\n",
      "man kostym kvinna klänning\n",
      "Predicted: klänning\n",
      "\n",
      "Churchill whiskey Löfven mjölk\n",
      "Predicted: glögg\n",
      "\n",
      "Sverige socialism Nordkorea kommunism\n",
      "Predicted: kommunism\n",
      "\n",
      "chef rik student fattig\n",
      "Predicted: kultiverad\n",
      "\n",
      "sitta sittandes stå ståendes\n",
      "Predicted: ståendes\n",
      "\n",
      "kaffe te öl vin\n",
      "Predicted: vin\n",
      "\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "new_examples = [    \n",
    "    'hockey klubba tennis racket',\n",
    "    'man kostym kvinna klänning',\n",
    "    'Churchill whiskey Löfven mjölk',\n",
    "    'Sverige socialism Nordkorea kommunism',\n",
    "    'chef rik student fattig',\n",
    "    'sitta sittandes stå ståendes',\n",
    "    'kaffe te öl vin',\n",
    "]\n",
    "print(evaluate(model, new_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We underestimated the student.\n",
    "\n",
    "If the words are closely related the model performs surpringsingly well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of vector space models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last task for this lab is to reflect on how one could use word space models in a practical application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 7</div>\n",
    "<div class=\"panel-body\">\n",
    "How could one apply word vectors in a recommendation system for books?\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can look at: genre, title, author, language, summary of the book and use them as to find books that are close in the n-dimensional model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
