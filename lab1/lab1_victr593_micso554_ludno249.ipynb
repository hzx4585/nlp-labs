{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "**Due date:** 2017-01-27\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students:** Victor Tranell (victr593), Michael Sörsäter (micso554), Ludvig Noring (ludno249)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will implement and compare the performance of two simple text classifiers: a Naive Bayes classifier and a classifier based on the averaged perceptron.\n",
    "\n",
    "The data set that you will use in this lab is the [review polarity data set](https://www.cs.cornell.edu/people/pabo/movie-review-data/) first used by [Pang and Lee (2004)](http://www.aclweb.org/anthology/P04-1035). This data set consists of 2,000 movie reviews, each of which has been tagged as either positive or negative towards the movie at hand. The data is originally distributed as a collection of text files. For this lab we have put all files into two JSON files, one for training and one for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the module for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nlp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads the training data and the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = nlp1.load_data(\"/home/TDDE09/labs/nlp1/review_polarity.train.json\")\n",
    "test_data = nlp1.load_data(\"/home/TDDE09/labs/nlp1/review_polarity.test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, each data instance is a pair whose first component is a document, represented as a list of tokens, and whose second component is the gold-standard polarity of the review&nbsp;&ndash; either positive (`pos`) or negative (`neg`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['this', 'film', 'is', 'extraordinarily', 'horrendous', 'and', \"i'm\", 'not', 'going', 'to', 'waste', 'any', 'more', 'words', 'on', 'it', '.'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "print(training_data[813])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two classifiers that you will implement in this lab should inherit from the following class, whose only method `predict` takes a document and returns the predicted class for that document (here: the polarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "\n",
    "    def predict(self, d):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that you will have do is to implement a function\n",
    "\n",
    "`accuracy(classifier, data)`\n",
    "\n",
    "that computes the accuracy of a classifier on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(classifier, data):        \n",
    "    return sum([classifier.predict(review[0]) == review[1] for review in data]) / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test this function by computing the accuracy of a Naive Bayes classifier on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    }
   ],
   "source": [
    "classifier = nlp1.NaiveBayesClassifier.train(training_data)\n",
    "print(accuracy(classifier, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 1</div>\n",
    "<div class=\"panel-body\">\n",
    "Provide your own implementation of the `accuracy()` function. Test your implementation by redoing the evaluation. You should get exactly the same results as before.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "**Hint:** Using an appropriate function from the `statistics` module, this problem can be solved in a one-liner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Naive Bayes classifier, you should complete the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "class MyNaiveBayesClassifier(Classifier):\n",
    "    \n",
    "    def __init__(self, pc, pp, pn):\n",
    "        self.pc = pc\n",
    "        self.pp = pp\n",
    "        self.pn = pn\n",
    "\n",
    "    def predict(self, data):\n",
    "        posclass = log(self.pc[0])\n",
    "        negclass = log(self.pc[1])\n",
    "        for word in data:\n",
    "            if word in self.pp:\n",
    "                posclass += log(self.pp[word])\n",
    "                negclass += log(self.pn[word])\n",
    "        if posclass > negclass:\n",
    "            return \"pos\"\n",
    "        else:\n",
    "            return \"neg\"\n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, data, k=1):\n",
    "        wordbag = set()\n",
    "\n",
    "        poslist = []\n",
    "        neglist = []\n",
    "        poscount = 0\n",
    "        for rev in data:\n",
    "            for word in rev[0]:\n",
    "                wordbag.add(word)\n",
    "            if(rev[-1] == 'pos'):\n",
    "                poscount += 1\n",
    "                poslist += rev[0]\n",
    "            else:\n",
    "                neglist += rev[0]\n",
    "                \n",
    "        posbag = Counter(poslist)\n",
    "        negbag = Counter(neglist)\n",
    "        \n",
    "        Pposbag = {}\n",
    "        Pnegbag = {}\n",
    "        \n",
    "        sumOfPosFreq = 0\n",
    "        for word in posbag:\n",
    "            sumOfPosFreq += posbag[word]\n",
    "            \n",
    "        sumOfNegFreq = 0\n",
    "        for word in negbag:\n",
    "            sumOfNegFreq += negbag[word]\n",
    "        \n",
    "        len_wordbag = len(wordbag)\n",
    "        for word in wordbag:\n",
    "            if(word in negbag):\n",
    "                Pnegbag[word] = (negbag[word] + k) / (sumOfNegFreq + k * len_wordbag)\n",
    "            else:\n",
    "                Pnegbag[word] = (k) / (sumOfNegFreq + k * len_wordbag)\n",
    "\n",
    "            if(word in posbag):\n",
    "                Pposbag[word] = (posbag[word] + k) / (sumOfPosFreq + k * len_wordbag)\n",
    "            else:\n",
    "                Pposbag[word] = (k) / (sumOfPosFreq + k * len_wordbag)\n",
    "                \n",
    "            \n",
    "\n",
    "        pc = [poscount / len(data), 1 - (poscount / len(data))]\n",
    "    \n",
    "        return cls(pc, Pposbag, Pnegbag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this skeleton the method `predict()` should implement the Naive Bayes classification rule. The method `train()` should return a new classifier that has been trained on the specified training data using maximum likelihood estimation with add-$k$ smoothing.\n",
    "\n",
    "To test your implementation, you can re-do the evaluation from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    }
   ],
   "source": [
    "classifier1 = MyNaiveBayesClassifier.train(training_data)\n",
    "print(accuracy(classifier1, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 2</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the two methods in `MyNaiveBayesClassifier`. Test your implementation by evaluating on the test data. Your results should be very similar to the ones that you got when you evaluated your accuracy function in Problem&nbsp;1.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaged perceptron classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code skeleton for the averaged perceptron classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyPerceptronClassifier(Classifier):\n",
    "    \n",
    "    def __init__(self, wp, wn):\n",
    "        self.wp = wp\n",
    "        self.wn = wn\n",
    "\n",
    "    def predict(self, x):\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for word in x:\n",
    "            if word in self.wp:\n",
    "                pos_score += self.wp[word]\n",
    "                neg_score += self.wn[word]\n",
    "                \n",
    "        return \"pos\" if pos_score >= neg_score else \"neg\"\n",
    "\n",
    "    @classmethod\n",
    "    def train(cls, data, n_epochs=1):\n",
    "        wp = {}\n",
    "        wn = {}\n",
    "        for review in data:\n",
    "            for word in review[0]:\n",
    "                wp[word] = 0\n",
    "                wn[word] = 0\n",
    "    \n",
    "        for e in range(n_epochs):\n",
    "            for review in data:\n",
    "                pos_class = 0\n",
    "                neg_class = 0\n",
    "                for word in review[0]:\n",
    "                    pos_class += wp[word]\n",
    "                    neg_class += wn[word] \n",
    "                    \n",
    "                if(pos_class >= neg_class):\n",
    "                    pred = \"pos\"\n",
    "                else:\n",
    "                    pred = \"neg\"\n",
    "                    \n",
    "                if(pred != review[1]):\n",
    "                    if(pred == \"pos\"):\n",
    "                        inc = -1\n",
    "                    else:\n",
    "                        inc = 1\n",
    "                    for word in review[0]:\n",
    "                        wp[word] += inc\n",
    "                        wn[word] += -1 * inc\n",
    "        \n",
    "        return cls(wp, wn)\n",
    "    \n",
    "    @classmethod\n",
    "    def train_avg(cls, data, n_epochs=1):\n",
    "        wp = {}\n",
    "        wn = {}\n",
    "        acc_p = {}\n",
    "        acc_n = {}\n",
    "        cnt = 1\n",
    "        for review in data:\n",
    "            for word in review[0]:\n",
    "                wp[word] = 0\n",
    "                wn[word] = 0\n",
    "                \n",
    "                acc_p[word] = 0\n",
    "                acc_n[word] = 0\n",
    "    \n",
    "        for e in range(n_epochs):\n",
    "            for review in data:\n",
    "                pos_class = 0\n",
    "                neg_class = 0\n",
    "                for word in review[0]:\n",
    "                    pos_class += wp[word]\n",
    "                    neg_class += wn[word] \n",
    "                if(pos_class >= neg_class):\n",
    "                    pred = \"pos\"\n",
    "                else:\n",
    "                    pred = \"neg\"\n",
    "                    \n",
    "                if(pred != review[1]):\n",
    "                    if(pred == \"pos\"):\n",
    "                        inc = -1\n",
    "                    else:\n",
    "                        inc = 1\n",
    "                    for word in review[0]:\n",
    "                        acc_p[word] += cnt * inc\n",
    "                        acc_n[word] += cnt * -1 * inc\n",
    "                        wp[word] += inc\n",
    "                        wn[word] += -1 * inc\n",
    "                        \n",
    "                cnt += 1\n",
    "        for word in wp:\n",
    "            wp[word] -= acc_p[word]/cnt\n",
    "            wn[word] -= acc_n[word]/cnt\n",
    "        \n",
    "        return cls(wp, wn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this skeleton, the method `predict()` should implement the perceptron classification rule. The method `train()` should return a new classifier that has been trained on the specified training data using averaged perceptron training for the specified number of epochs.\n",
    "\n",
    "To test your implementation, as before you can train a classifier on the training data and evaluate it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch    : 0.64\n",
      "2 epoch    : 0.75\n",
      "\n",
      "1 epoch avg: 0.745\n",
      "2 epoch avg: 0.79\n"
     ]
    }
   ],
   "source": [
    "classifier2_1 = MyPerceptronClassifier.train(training_data, 1)\n",
    "classifier2_2 = MyPerceptronClassifier.train(training_data, 2)\n",
    "print(\"1 epoch    :\", accuracy(classifier2_1, test_data))\n",
    "print(\"2 epoch    :\", accuracy(classifier2_2, test_data))\n",
    "\n",
    "print()\n",
    "classifier2_1 = MyPerceptronClassifier.train_avg(training_data, 1)\n",
    "classifier2_2 = MyPerceptronClassifier.train_avg(training_data, 2)\n",
    "print(\"1 epoch avg:\", accuracy(classifier2_1, test_data))\n",
    "print(\"2 epoch avg:\", accuracy(classifier2_2, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 3</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the two methods in `MyPerceptronClassifier`. Test your implementation by evaluating on the test data. You should get results in the 70&ndash;80% range. What happens if you repeat the experiment but do not do averaging? What happens when you train the classifier for two epochs? Enter your results into the table below.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr><td></td><td>averaging</td><td>no averaging</td></tr>\n",
    "<tr><td>1 epoch</td><td>0.745</td><td>0.64</td></tr>\n",
    "<tr><td>2 epochs</td><td>0.79</td><td>0.75</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching to binary features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lab so far, a document is represented as a list of the words that occur in it. For sentiment classification, several authors have suggested that a *binary* document representation, where each word is represented only once, can produce better results. In the last problem you will try to confirm this finding.\n",
    "\n",
    "Your task is to implement a function `binarize()` that converts data into the binary representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(data):\n",
    "    new_data = []\n",
    "    [new_data.append([list(set(review[0])), review[1]]) for review in data]\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is to be used in the following context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n",
      "0.845\n"
     ]
    }
   ],
   "source": [
    "binarized_training_data = binarize(training_data)\n",
    "binarized_test_data = binarize(test_data)\n",
    "\n",
    "classifier3 = MyNaiveBayesClassifier.train(binarized_training_data)\n",
    "print(accuracy(classifier3, binarized_test_data))\n",
    "\n",
    "classifier4 = MyPerceptronClassifier.train(binarized_training_data)\n",
    "print(accuracy(classifier4, binarized_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 4</div>\n",
    "<div class=\"panel-body\">\n",
    "Implement the `binarize()` function and run the evaluation. What do you observe? Summarise your results in one or two sentences.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the binarized data the accuracy improve a lot.\n",
    "By binarizing the data, the information is more concentrated and the \"keywords\" such as \"tremendous\" and \"terrible\" is weighted more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
